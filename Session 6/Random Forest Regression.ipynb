{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Driven Modeling 3: Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import time\n",
    "import matplotlib.patches as mpatches\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold, cross_validate, LeaveOneOut, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "\n",
    "# Set matplotlib parameters for plotting\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['axes.linewidth'] = 1.5\n",
    "matplotlib.rcParams['xtick.major.size'] = 8\n",
    "matplotlib.rcParams['xtick.major.width'] = 2\n",
    "matplotlib.rcParams['ytick.major.size'] = 8\n",
    "matplotlib.rcParams['ytick.major.width'] = 2\n",
    "matplotlib.rcParams['figure.dpi'] = 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the housing dataset\n",
    "dataset = fetch_california_housing()\n",
    "\n",
    "# extract the features X and reponse y \n",
    "X_full, y_full = dataset.data, dataset.target\n",
    "# check dataset sizes\n",
    "print(X_full.shape)\n",
    "\n",
    "# print out the feature names\n",
    "X_names = dataset.feature_names\n",
    "print(X_names)\n",
    "y_name = 'Housing Price'\n",
    "\n",
    "# Take only 2 features to make visualization easier\n",
    "# Feature 0 and feature 1 have very different scales and distributions \n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(X_full[:,0], X_full[:,2], s = 30, alpha = 0.5)\n",
    "ax.set_xlabel(X_names[0])\n",
    "ax.set_ylabel(X_names[1])\n",
    "\n",
    "# plot the last two features which gives the shape of the state of California! \n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(X_full[:,-1], X_full[:,-2], s = 30, alpha = 0.5)\n",
    "ax.set_xlabel(X_names[-1])\n",
    "ax.set_ylabel(X_names[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Standardize the data to a zero mean and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data \n",
    "# Standardize \n",
    "scaler = StandardScaler().fit(X_full)\n",
    "Xs = scaler.transform(X_full)\n",
    "\n",
    "# Export the mean and std of the original data  \n",
    "X_std = scaler.scale_ # std for each x variable\n",
    "print('The std of each column in original X:')\n",
    "print(X_std)\n",
    "\n",
    "X_mean = scaler.mean_ # mean for each x variable\n",
    "print('The std of each column in original X:')\n",
    "print(X_std)\n",
    "\n",
    "# Check if there have a unit variance \n",
    "Xs_std = np.std(Xs, axis = 0) \n",
    "print('The std of each column in standardized X:')\n",
    "print(Xs_std)\n",
    "\n",
    "Xs_mean = np.mean(Xs, axis = 0)\n",
    "print('The mean of each column standardized X:')\n",
    "print(Xs_mean)\n",
    "\n",
    "# Feature 0 and feature 1 after standardization\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(Xs[:,0], Xs[:,2], s = 30, alpha = 0.5)\n",
    "ax.set_xlabel(X_names[0])\n",
    "ax.set_ylabel(X_names[1])\n",
    "\n",
    "# Last two features after standardization\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(Xs[:,-1], Xs[:,-2], s = 30, alpha = 0.5)\n",
    "ax.set_xlabel(X_names[-1])\n",
    "ax.set_ylabel(X_names[-2])\n",
    "\n",
    "# Assign Xs to X\n",
    "X = Xs.copy()\n",
    "y = y_full.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split the data into training and test set, set up cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# check train and test set sizes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "                               \n",
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, y, estimator): \n",
    "    '''\n",
    "    Cross-validation\n",
    "    '''\n",
    "    loo = LeaveOneOut()\n",
    "    scores  = cross_validate(estimator, X, y, cv = loo,\n",
    "                                scoring=('neg_mean_squared_error', 'r2'),\n",
    "                                return_train_score=True)\n",
    "    # RMSE for repeated 10 fold test data \n",
    "    test_RMSE = np.sqrt(np.abs(scores['test_neg_mean_squared_error'])) \n",
    "    test_RMSE_mean = np.mean(test_RMSE)\n",
    "    test_RMSE_std = np.std(test_RMSE)\n",
    "    \n",
    "    train_r2 = scores['train_r2'] \n",
    "    train_r2_mean =  np.mean(train_r2)\n",
    "    train_r2_std = np.std(train_r2)\n",
    "    \n",
    "    return [test_RMSE_mean, test_RMSE_std, train_r2_mean, train_r2_std]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Find the optimal number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off warnings for calculating r2 of a single point\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "# Train the random forest model using Grid search\n",
    "train_flag = True\n",
    "\n",
    "if train_flag:\n",
    "    # grid search for n_estimator. Can change it based on your own system.\n",
    "    n_estimators_grid = range(1,51, 1)\n",
    "    test_RMSE_m = np.zeros(len(n_estimators_grid)) \n",
    "    progress = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i, n_estimators_i in enumerate(n_estimators_grid):\n",
    "        progress += 1\n",
    "        per = progress/len(n_estimators_grid)*100\n",
    "        print('Training {0:.5f} % Done!'.format(per))\n",
    "            \n",
    "        rf = RandomForestRegressor(n_estimators = n_estimators_i,random_state=0)\n",
    "                                                                            \n",
    "        [test_RMSE_mean, test_RMSE_std, train_r2_mean, train_r2_std] = cross_validation(X_train, y_train, rf)\n",
    "        test_RMSE_m[i] = test_RMSE_mean\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"Tuning hyperparameter takes {0:.2f} minutes\".format((end_time-start_time)/60.0))\n",
    "    \n",
    "    # Final the optimal model\n",
    "    test_RMSE_m = np.around(test_RMSE_m, decimals = 3)\n",
    "    opt_ind = np.unravel_index(np.argmin(test_RMSE_m, axis=None), test_RMSE_m.shape)\n",
    "    n_estimators_opt = n_estimators_grid[opt_ind[0]]\n",
    "\n",
    "else: \n",
    "    n_estimators_opt = 50\n",
    "\n",
    "print('The optimal number of estimator is: {}'.format(n_estimators_opt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Fit the model using the optimal estimator    \n",
    "rf_opt = RandomForestRegressor(n_estimators = n_estimators_opt, random_state=0)                                     \n",
    "rf_opt.fit(X_train, y_train)\n",
    "\n",
    "# Calculated the error on test data\n",
    "y_predict_test = rf_opt.predict(X_test)\n",
    "RMSE_test = np.sqrt(mean_squared_error(y_test, y_predict_test))\n",
    "\n",
    "print('RMSE of test set is: {}'.format(RMSE_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
